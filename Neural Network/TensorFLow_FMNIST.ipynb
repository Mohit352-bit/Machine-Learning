{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNTduPsgUmN4x0vQ7xAl5fr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"q5T2whusABi5","executionInfo":{"status":"ok","timestamp":1667394262359,"user_tz":-330,"elapsed":3764,"user":{"displayName":"mohit srivastava","userId":"06485141586567620411"}}},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["#importing inbuilt dataset in tensorflow\n","# there are total 10 type of clothing in this data and there image are reduced to size 28x28 and is in grayscale so less computing is required \n","fmnist = tf.keras.datasets.fashion_mnist"],"metadata":{"id":"FIwvR-ofCEhH","executionInfo":{"status":"ok","timestamp":1667394262359,"user_tz":-330,"elapsed":3,"user":{"displayName":"mohit srivastava","userId":"06485141586567620411"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#as dataset is sotred in the form of arrays so we need to first extract them in different variables\n","\n","(train_image , train_label) , (test_image , test_label) = fmnist.load_data()"],"metadata":{"id":"UWRJffWFCsfr","executionInfo":{"status":"ok","timestamp":1667394263094,"user_tz":-330,"elapsed":737,"user":{"displayName":"mohit srivastava","userId":"06485141586567620411"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#visualising the dataset of fmnist on graph\n","\n","#print(train_image[0])\n","\n","# each clothing is labled from 0 to 9 and this sneaker is marked 9 this is what the below code will display\n","print(train_label[0])\n","\n","plt.imshow(train_image[0] , cmap='gray')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"Auh-HreBDLwF","executionInfo":{"status":"ok","timestamp":1667394263903,"user_tz":-330,"elapsed":811,"user":{"displayName":"mohit srivastava","userId":"06485141586567620411"}},"outputId":"889f68cb-7002-4296-d363-6d34eb9ac6d6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["9\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fbe38c1c450>"]},"metadata":{},"execution_count":5},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# each value in train_image is in range of 0 to 255 as it depicts RGB so to normalise (making it to standard scale between 0 and 1) it we need to divide it by 255\n","\n","train_image = train_image / 255\n","test_image = test_image / 255"],"metadata":{"id":"ulA1rPnFESZP","executionInfo":{"status":"ok","timestamp":1667394264499,"user_tz":-330,"elapsed":1,"user":{"displayName":"mohit srivastava","userId":"06485141586567620411"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4p0sMHXpHkxg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Building the Classification model\n","\n"],"metadata":{"id":"MBWYhFYQIVOq"}},{"cell_type":"markdown","source":[" **Sequential**: That defines a sequence of layers in the neural network.\n","\n","**Flatten**:  our images were a 28x28 pixel matrix when we printed them out.Flatten just takes that 28x28 square matrix and turns it into a 1-dimensional array and the send the values inside the array as input to the first layer of neuron\n","\n","**Dense**: Adds a layer of neurons\n","\n","**Activation**\n","Each layer of neurons need an activation function to tell them what to do. There are a lot of options, but just use these for now:\n","\n","**ReLU** effectively means:\n","\n","if x > 0: \n","  return x\n","\n","else: \n","  return 0\n","  \n","In other words, it only passes values 0 or greater to the next layer in the network."],"metadata":{"id":"7Ej5as2TIM2h"}},{"cell_type":"code","source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Flatten(input_shape =(28,28)),\n","    tf.keras.layers.Dense(512 , activation=tf.nn.relu),\n","    tf.keras.layers.Dense(10 , activation= tf.nn.softmax)\n","\n","])"],"metadata":{"id":"R5Ir8MC0H3uu","executionInfo":{"status":"ok","timestamp":1667391161059,"user_tz":-330,"elapsed":413,"user":{"displayName":"mohit srivastava","userId":"06485141586567620411"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"92rt99YcUcal","executionInfo":{"status":"ok","timestamp":1667392455150,"user_tz":-330,"elapsed":410,"user":{"displayName":"mohit srivastava","userId":"06485141586567620411"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["First we run the whole on 128 nodes and we get accuracy 88.829 the we use 512 nodes and we get 89.891 from this we can get that there is no large increase\n"," in accuracy.We use larger number of nodes to when the data is too complex(i.e. if we use coloured images instead of grey scaled) and the data we are handling is not that much complex so we didn't get much importvement in the accuracy bold text"],"metadata":{"id":"kPjo76T5VeKh"}},{"cell_type":"code","source":["# .compile is the function where the model checks th error and analyse for better result\n","# every time the accuracy of model is improved \n","\n","\n","model.compile(optimizer = tf.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(train_image, train_label, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"En7LRKuoKs9M","executionInfo":{"status":"ok","timestamp":1667392098917,"user_tz":-330,"elapsed":923313,"user":{"displayName":"mohit srivastava","userId":"06485141586567620411"}},"outputId":"0e41ab36-8ac3-41e6-8d4b-5c473028e115"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.4760 - accuracy: 0.8308\n","Epoch 2/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.3584 - accuracy: 0.8704\n","Epoch 3/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.3233 - accuracy: 0.8814\n","Epoch 4/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.2958 - accuracy: 0.8910\n","Epoch 5/100\n","1875/1875 [==============================] - 8s 5ms/step - loss: 0.2782 - accuracy: 0.8964\n","Epoch 6/100\n","1875/1875 [==============================] - 13s 7ms/step - loss: 0.2641 - accuracy: 0.9012\n","Epoch 7/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.2506 - accuracy: 0.9056\n","Epoch 8/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.2405 - accuracy: 0.9087\n","Epoch 9/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.2316 - accuracy: 0.9119\n","Epoch 10/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.2203 - accuracy: 0.9175\n","Epoch 11/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.2115 - accuracy: 0.9203\n","Epoch 12/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.2055 - accuracy: 0.9222\n","Epoch 13/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1977 - accuracy: 0.9251\n","Epoch 14/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1877 - accuracy: 0.9289\n","Epoch 15/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1836 - accuracy: 0.9308\n","Epoch 16/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1770 - accuracy: 0.9328\n","Epoch 17/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1723 - accuracy: 0.9342\n","Epoch 18/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.1660 - accuracy: 0.9371\n","Epoch 19/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1635 - accuracy: 0.9377\n","Epoch 20/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1562 - accuracy: 0.9409\n","Epoch 21/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1516 - accuracy: 0.9416\n","Epoch 22/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1499 - accuracy: 0.9443\n","Epoch 23/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1396 - accuracy: 0.9475\n","Epoch 24/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1384 - accuracy: 0.9475\n","Epoch 25/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.1373 - accuracy: 0.9479\n","Epoch 26/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1314 - accuracy: 0.9502\n","Epoch 27/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1289 - accuracy: 0.9512\n","Epoch 28/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1271 - accuracy: 0.9528\n","Epoch 29/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1249 - accuracy: 0.9523\n","Epoch 30/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1198 - accuracy: 0.9545\n","Epoch 31/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.1173 - accuracy: 0.9553\n","Epoch 32/100\n","1875/1875 [==============================] - 10s 6ms/step - loss: 0.1152 - accuracy: 0.9561\n","Epoch 33/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.1121 - accuracy: 0.9580\n","Epoch 34/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.1077 - accuracy: 0.9596\n","Epoch 35/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.1074 - accuracy: 0.9594\n","Epoch 36/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.1041 - accuracy: 0.9607\n","Epoch 37/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.1032 - accuracy: 0.9607\n","Epoch 38/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0986 - accuracy: 0.9626\n","Epoch 39/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0986 - accuracy: 0.9635\n","Epoch 40/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0945 - accuracy: 0.9650\n","Epoch 41/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0968 - accuracy: 0.9638\n","Epoch 42/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0922 - accuracy: 0.9650\n","Epoch 43/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0905 - accuracy: 0.9666\n","Epoch 44/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0871 - accuracy: 0.9674\n","Epoch 45/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0873 - accuracy: 0.9671\n","Epoch 46/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0857 - accuracy: 0.9676\n","Epoch 47/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0841 - accuracy: 0.9684\n","Epoch 48/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0825 - accuracy: 0.9692\n","Epoch 49/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0809 - accuracy: 0.9688\n","Epoch 50/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0804 - accuracy: 0.9704\n","Epoch 51/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0779 - accuracy: 0.9703\n","Epoch 52/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0745 - accuracy: 0.9723\n","Epoch 53/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0747 - accuracy: 0.9718\n","Epoch 54/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0738 - accuracy: 0.9718\n","Epoch 55/100\n","1875/1875 [==============================] - 11s 6ms/step - loss: 0.0740 - accuracy: 0.9721\n","Epoch 56/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0706 - accuracy: 0.9736\n","Epoch 57/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0722 - accuracy: 0.9733\n","Epoch 58/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0671 - accuracy: 0.9747\n","Epoch 59/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0674 - accuracy: 0.9750\n","Epoch 60/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0680 - accuracy: 0.9749\n","Epoch 61/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0656 - accuracy: 0.9754\n","Epoch 62/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0636 - accuracy: 0.9757\n","Epoch 63/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0641 - accuracy: 0.9760\n","Epoch 64/100\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.0644 - accuracy: 0.9760\n","Epoch 65/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0633 - accuracy: 0.9765\n","Epoch 66/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0592 - accuracy: 0.9777\n","Epoch 67/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0633 - accuracy: 0.9770\n","Epoch 68/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0588 - accuracy: 0.9782\n","Epoch 69/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0619 - accuracy: 0.9768\n","Epoch 70/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0562 - accuracy: 0.9788\n","Epoch 71/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0575 - accuracy: 0.9789\n","Epoch 72/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0567 - accuracy: 0.9792\n","Epoch 73/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0554 - accuracy: 0.9801\n","Epoch 74/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0525 - accuracy: 0.9800\n","Epoch 75/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0573 - accuracy: 0.9787\n","Epoch 76/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0534 - accuracy: 0.9799\n","Epoch 77/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0537 - accuracy: 0.9801\n","Epoch 78/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0503 - accuracy: 0.9812\n","Epoch 79/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0528 - accuracy: 0.9805\n","Epoch 80/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0518 - accuracy: 0.9811\n","Epoch 81/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0503 - accuracy: 0.9809\n","Epoch 82/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0493 - accuracy: 0.9816\n","Epoch 83/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0513 - accuracy: 0.9811\n","Epoch 84/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0485 - accuracy: 0.9821\n","Epoch 85/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0466 - accuracy: 0.9822\n","Epoch 86/100\n","1875/1875 [==============================] - 8s 5ms/step - loss: 0.0466 - accuracy: 0.9823\n","Epoch 87/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0481 - accuracy: 0.9829\n","Epoch 88/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0475 - accuracy: 0.9821\n","Epoch 89/100\n","1875/1875 [==============================] - 8s 5ms/step - loss: 0.0498 - accuracy: 0.9817\n","Epoch 90/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0441 - accuracy: 0.9837\n","Epoch 91/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0458 - accuracy: 0.9837\n","Epoch 92/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0432 - accuracy: 0.9844\n","Epoch 93/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0446 - accuracy: 0.9837\n","Epoch 94/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0435 - accuracy: 0.9845\n","Epoch 95/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0440 - accuracy: 0.9844\n","Epoch 96/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0415 - accuracy: 0.9843\n","Epoch 97/100\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.0436 - accuracy: 0.9841\n","Epoch 98/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0422 - accuracy: 0.9850\n","Epoch 99/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0412 - accuracy: 0.9851\n","Epoch 100/100\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0395 - accuracy: 0.9855\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f9d010bd9d0>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# to evaluate the accuracy of the model\n","model.evaluate(test_image, test_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VF9ZE_WyS8Vs","executionInfo":{"status":"ok","timestamp":1667392159558,"user_tz":-330,"elapsed":1544,"user":{"displayName":"mohit srivastava","userId":"06485141586567620411"}},"outputId":"983a0afc-720e-41ad-982e-45508c26e32f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.8601 - accuracy: 0.8916\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.8600794076919556, 0.8916000127792358]"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["##Epoch\n","if we want to stop the epoch at a particular accuracy or loss value so that we donot have to run the whole epoch, we can use ***Callbacks*** .\n","\n","***Log*** - it stores every data like accuracy value , loss value , time etc of the epoch and '.get' can be used to get particular data we want\n"],"metadata":{"id":"CTpsiPHmYXkw"}},{"cell_type":"code","source":["class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self , epoch, log={}):\n","    if(log.get('loss') < 0.26 ):\n","      print('nLoss is lower than 0.26 so cancelling training!')\n","      self.model.stop_training = True\n","  \n","#Initantiating callback class\n","\n","callbackit = myCallback()\n"],"metadata":{"id":"1XXT2h63Y537","executionInfo":{"status":"ok","timestamp":1667394345109,"user_tz":-330,"elapsed":1,"user":{"displayName":"mohit srivastava","userId":"06485141586567620411"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Flatten(input_shape =(28,28)),\n","    tf.keras.layers.Dense(128 , activation=tf.nn.relu),\n","    tf.keras.layers.Dense(10 , activation= tf.nn.softmax)\n","\n","])\n","\n","model.compile(optimizer = tf.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(train_image, train_label, epochs=40 , callbacks= [callbackit])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BwGR3V4OatZO","executionInfo":{"status":"ok","timestamp":1667394393173,"user_tz":-330,"elapsed":45441,"user":{"displayName":"mohit srivastava","userId":"06485141586567620411"}},"outputId":"a29842a7-277c-47a3-a4c8-8901a93b9a06"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.4982 - accuracy: 0.8254\n","Epoch 2/40\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.3729 - accuracy: 0.8667\n","Epoch 3/40\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.3348 - accuracy: 0.8768\n","Epoch 4/40\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.3124 - accuracy: 0.8851\n","Epoch 5/40\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.2948 - accuracy: 0.8905\n","Epoch 6/40\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.2806 - accuracy: 0.8964\n","Epoch 7/40\n","1875/1875 [==============================] - 5s 3ms/step - loss: 0.2676 - accuracy: 0.9001\n","Epoch 8/40\n","1872/1875 [============================>.] - ETA: 0s - loss: 0.2583 - accuracy: 0.9040nLoss is lower than 0.26 so cancelling training!\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.2583 - accuracy: 0.9040\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbe3443c510>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":[],"metadata":{"id":"gZ-1oNg1a3E9"},"execution_count":null,"outputs":[]}]}