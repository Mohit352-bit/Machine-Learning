{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "q5T2whusABi5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FIwvR-ofCEhH"
   },
   "outputs": [],
   "source": [
    "#importing inbuilt dataset in tensorflow\n",
    "# there are total 10 type of clothing in this data and there image are reduced to size 28x28 and is in grayscale so less computing is required \n",
    "fmnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UWRJffWFCsfr"
   },
   "outputs": [],
   "source": [
    "#as dataset is sotred in the form of arrays so we need to first extract them in different variables\n",
    "\n",
    "(train_image , train_label) , (test_image , test_label) = fmnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "Auh-HreBDLwF",
    "outputId": "889f68cb-7002-4296-d363-6d34eb9ac6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2f2cdb816d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualising the dataset of fmnist on graph\n",
    "\n",
    "#print(train_image[0])\n",
    "\n",
    "# each clothing is labled from 0 to 9 and this sneaker is marked 9 this is what the below code will display\n",
    "print(train_label[0])\n",
    "\n",
    "plt.imshow(train_image[0] , cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ulA1rPnFESZP"
   },
   "outputs": [],
   "source": [
    "# each value in train_image is in range of 0 to 255 as it depicts RGB so to normalise (making it to standard scale between 0 and 1) it we need to divide it by 255\n",
    "\n",
    "train_image = train_image / 255\n",
    "test_image = test_image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4p0sMHXpHkxg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBWYhFYQIVOq"
   },
   "source": [
    "## Building the Classification model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ej5as2TIM2h"
   },
   "source": [
    " **Sequential**: That defines a sequence of layers in the neural network.\n",
    "\n",
    "**Flatten**:  our images were a 28x28 pixel matrix when we printed them out.Flatten just takes that 28x28 square matrix and turns it into a 1-dimensional array and the send the values inside the array as input to the first layer of neuron\n",
    "\n",
    "**Dense**: Adds a layer of neurons\n",
    "\n",
    "**Activation**\n",
    "Each layer of neurons need an activation function to tell them what to do. There are a lot of options, but just use these for now:\n",
    "\n",
    "**ReLU** effectively means:\n",
    "\n",
    "if x > 0: \n",
    "  return x\n",
    "\n",
    "else: \n",
    "  return 0\n",
    "  \n",
    "In other words, it only passes values 0 or greater to the next layer in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5Ir8MC0H3uu"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape =(28,28)),\n",
    "    tf.keras.layers.Dense(512 , activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10 , activation= tf.nn.softmax)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92rt99YcUcal"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPjo76T5VeKh"
   },
   "source": [
    "First we run the whole on 128 nodes and we get accuracy 88.829 the we use 512 nodes and we get 89.891 from this we can get that there is no large increase\n",
    " in accuracy.We use larger number of nodes to when the data is too complex(i.e. if we use coloured images instead of grey scaled) and the data we are handling is not that much complex so we didn't get much importvement in the accuracy bold text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "En7LRKuoKs9M",
    "outputId": "0e41ab36-8ac3-41e6-8d4b-5c473028e115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4760 - accuracy: 0.8308\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3584 - accuracy: 0.8704\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3233 - accuracy: 0.8814\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2958 - accuracy: 0.8910\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.2782 - accuracy: 0.8964\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2641 - accuracy: 0.9012\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2506 - accuracy: 0.9056\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2405 - accuracy: 0.9087\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2316 - accuracy: 0.9119\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2203 - accuracy: 0.9175\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2115 - accuracy: 0.9203\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2055 - accuracy: 0.9222\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1977 - accuracy: 0.9251\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1877 - accuracy: 0.9289\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1836 - accuracy: 0.9308\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1770 - accuracy: 0.9328\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1723 - accuracy: 0.9342\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1660 - accuracy: 0.9371\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1635 - accuracy: 0.9377\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1562 - accuracy: 0.9409\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1516 - accuracy: 0.9416\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1499 - accuracy: 0.9443\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1396 - accuracy: 0.9475\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1384 - accuracy: 0.9475\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1373 - accuracy: 0.9479\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1314 - accuracy: 0.9502\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1289 - accuracy: 0.9512\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1271 - accuracy: 0.9528\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1249 - accuracy: 0.9523\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1198 - accuracy: 0.9545\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1173 - accuracy: 0.9553\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1152 - accuracy: 0.9561\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1121 - accuracy: 0.9580\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1077 - accuracy: 0.9596\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1074 - accuracy: 0.9594\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1041 - accuracy: 0.9607\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1032 - accuracy: 0.9607\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0986 - accuracy: 0.9626\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0986 - accuracy: 0.9635\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0945 - accuracy: 0.9650\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0968 - accuracy: 0.9638\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0922 - accuracy: 0.9650\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0905 - accuracy: 0.9666\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0871 - accuracy: 0.9674\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0873 - accuracy: 0.9671\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0857 - accuracy: 0.9676\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0841 - accuracy: 0.9684\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0825 - accuracy: 0.9692\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0809 - accuracy: 0.9688\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0804 - accuracy: 0.9704\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0779 - accuracy: 0.9703\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0745 - accuracy: 0.9723\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0747 - accuracy: 0.9718\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0738 - accuracy: 0.9718\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0740 - accuracy: 0.9721\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0706 - accuracy: 0.9736\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0722 - accuracy: 0.9733\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0671 - accuracy: 0.9747\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0674 - accuracy: 0.9750\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0680 - accuracy: 0.9749\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0656 - accuracy: 0.9754\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0636 - accuracy: 0.9757\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0641 - accuracy: 0.9760\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0644 - accuracy: 0.9760\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0633 - accuracy: 0.9765\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0592 - accuracy: 0.9777\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0633 - accuracy: 0.9770\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0588 - accuracy: 0.9782\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0619 - accuracy: 0.9768\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0562 - accuracy: 0.9788\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0575 - accuracy: 0.9789\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0567 - accuracy: 0.9792\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0554 - accuracy: 0.9801\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0525 - accuracy: 0.9800\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0573 - accuracy: 0.9787\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0534 - accuracy: 0.9799\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0537 - accuracy: 0.9801\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0503 - accuracy: 0.9812\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0528 - accuracy: 0.9805\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0518 - accuracy: 0.9811\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0503 - accuracy: 0.9809\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0493 - accuracy: 0.9816\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0513 - accuracy: 0.9811\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0485 - accuracy: 0.9821\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0466 - accuracy: 0.9822\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0466 - accuracy: 0.9823\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0481 - accuracy: 0.9829\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0475 - accuracy: 0.9821\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0498 - accuracy: 0.9817\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0441 - accuracy: 0.9837\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0458 - accuracy: 0.9837\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0432 - accuracy: 0.9844\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0446 - accuracy: 0.9837\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0435 - accuracy: 0.9845\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0440 - accuracy: 0.9844\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0415 - accuracy: 0.9843\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0436 - accuracy: 0.9841\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0422 - accuracy: 0.9850\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0412 - accuracy: 0.9851\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0395 - accuracy: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9d010bd9d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .compile is the function where the model checks th error and analyse for better result\n",
    "# every time the accuracy of model is improved \n",
    "\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_image, train_label, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VF9ZE_WyS8Vs",
    "outputId": "983a0afc-720e-41ad-982e-45508c26e32f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8601 - accuracy: 0.8916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8600794076919556, 0.8916000127792358]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to evaluate the accuracy of the model\n",
    "model.evaluate(test_image, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTpsiPHmYXkw"
   },
   "source": [
    "##Epoch\n",
    "if we want to stop the epoch at a particular accuracy or loss value so that we donot have to run the whole epoch, we can use ***Callbacks*** .\n",
    "\n",
    "***Log*** - it stores every data like accuracy value , loss value , time etc of the epoch and '.get' can be used to get particular data we want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XXT2h63Y537"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self , epoch, log={}):\n",
    "    if(log.get('loss') < 0.26 ):\n",
    "      print('nLoss is lower than 0.26 so cancelling training!')\n",
    "      self.model.stop_training = True\n",
    "  \n",
    "#Initantiating callback class\n",
    "\n",
    "callbackit = myCallback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwGR3V4OatZO",
    "outputId": "a29842a7-277c-47a3-a4c8-8901a93b9a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4982 - accuracy: 0.8254\n",
      "Epoch 2/40\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3729 - accuracy: 0.8667\n",
      "Epoch 3/40\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3348 - accuracy: 0.8768\n",
      "Epoch 4/40\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3124 - accuracy: 0.8851\n",
      "Epoch 5/40\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2948 - accuracy: 0.8905\n",
      "Epoch 6/40\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2806 - accuracy: 0.8964\n",
      "Epoch 7/40\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2676 - accuracy: 0.9001\n",
      "Epoch 8/40\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.2583 - accuracy: 0.9040nLoss is lower than 0.26 so cancelling training!\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2583 - accuracy: 0.9040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe3443c510>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape =(28,28)),\n",
    "    tf.keras.layers.Dense(128 , activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10 , activation= tf.nn.softmax)\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_image, train_label, epochs=40 , callbacks= [callbackit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gZ-1oNg1a3E9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.4366 - accuracy: 0.8409\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2905 - accuracy: 0.8934\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2458 - accuracy: 0.9087\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.2125 - accuracy: 0.9205\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.1863 - accuracy: 0.9301\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.1654 - accuracy: 0.9378\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.1448 - accuracy: 0.9449\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.1264 - accuracy: 0.9526\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1110 - accuracy: 0.9579\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0976 - accuracy: 0.9633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f2ca8b9f70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.ops.metrics_impl import accuracy\n",
    "from tensorflow.python import metrics\n",
    "cnn_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64 ,(3,3) , activation='relu' ,input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3) , activation =\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128 , activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    \n",
    "])\n",
    "cnn_model.compile(optimizer = 'adam' , loss =\"sparse_categorical_crossentropy\" , metrics=['accuracy'])\n",
    "cnn_model.fit(train_image, train_label, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m physical_devices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mset_memory_growth(\u001b[43mphysical_devices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m,\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
